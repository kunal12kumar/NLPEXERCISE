{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836998ba-167e-436f-be13-0ce480773312",
   "metadata": {},
   "source": [
    "# in this we will do stemmming in the process of stemmming we stemming of word to its stem to the affixes and suffixes like word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebfa8cb-aefd-42c5-b5c2-552b66d23bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2ec8d0-fcec-479a-b031-30bcf4603b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74f162eb-4a87-421d-9e05-3e9a1c795545",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7211c90b-1a30-40cd-9831-564755874375",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\", \"eaten\", \"eat\" , \"goes\", \"go\" , \"went\" ,\"history\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "776aa02f-81ee-4540-9de0-93737ddf202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eaten\n",
      "eat\n",
      "goe\n",
      "go\n",
      "went\n",
      "histori\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d06c5e9-605c-4347-8cf7-1a6ebd9e5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now doing stemming by SnowballStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6db96c84-d505-4ebc-990c-82e1b0f3ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowstemming=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "557cafbd-7b24-4bfd-836b-38e2d8ba8bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eaten\n",
      "eat\n",
      "goe\n",
      "go\n",
      "went\n",
      "histori\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(snowstemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727fd7de-6768-44e7-8988-83a74ff06b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to remove suffix and prefix from the words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8106e2e2-14d4-42d8-8e7b-989cacec4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "408dc521-56ea-488b-b619-7cf596ebb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexpstem=RegexpStemmer('ing$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4312abd7-306f-4a17-8f31-547b717142fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eaten\n",
      "eat\n",
      "goes\n",
      "go\n",
      "went\n",
      "history\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(regexpstem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc46b547-fc99-46b6-955f-bf289f4e97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nOw we use lemitizer to get more accuracy because it use something its own list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "821cbb89-1d5b-4ddf-8e5c-816d88dd75b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ec9d604-98d4-4df2-9fa6-151ac6e1f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "lematizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7d15853-ae36-43ab-8000-f020873c7006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating\n",
      "eaten\n",
      "eat\n",
      "go\n",
      "go\n",
      "went\n",
      "history\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(lematizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76952afa-5177-4745-b94e-eaca75131ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
